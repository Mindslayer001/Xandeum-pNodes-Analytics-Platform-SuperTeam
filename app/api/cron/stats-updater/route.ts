import { NextResponse } from 'next/server';
import db from '@/lib/db';
import { getStats } from '@/lib/xandeum-client';
import { refreshNetworkStatsCache } from '@/lib/network-stats-service';

export const dynamic = 'force-dynamic';
export const maxDuration = 300; // 5 minutes max

// Helper function to log errors to database
async function logErrorToDb(source: string, phase: string, error: string, nodeId?: string, details?: string) {
    try {
        await db.errorLog.create({
            data: {
                source,
                phase,
                nodeId: nodeId || null,
                error,
                details: details || null
            }
        });
    } catch (dbError: any) {
        console.error("Failed to log error to database:", dbError.message);
    }
}

export async function POST() {
    const startTime = Date.now();
    const errors: Array<{ node: string; error: string; phase: string }> = [];
    let nodesUpdated = 0;
    let snapshotsCreated = 0;
    let nodesProcessed = 0;

    // Stats counters
    let activeNodesCount = 0;
    let inactiveNodesCount = 0;
    let totalNetworkStorage = 0;
    let totalNetworkCredits = BigInt(0); // Using BigInt for credits to match schema

    try {
        console.log("üìä Stats Updater Triggered");

        // Get all nodes from database to update their stats
        const nodes = await db.node.findMany({
            select: {
                ip: true,
                pubkey: true,
                credits: true // Need credits for aggregation
            }
        });

        if (!nodes || nodes.length === 0) {
            console.warn("‚ö†Ô∏è No nodes found in database");
            return NextResponse.json({
                success: false,
                message: "No nodes found in database",
                nodesUpdated: 0,
                errors: []
            });
        }

        console.log(`üì¶ Updating stats for ${nodes.length} nodes...`);

        const snapshots: any[] = [];

        // Process nodes individually with progressive updates
        for (const node of nodes) {
            nodesProcessed++;

            try {
                // Fetch stats for this node
                // IPs are now stored without ports, so append :6000 for RPC call
                const stats = await getStats(`${node.ip}:6000`);

                if (!stats) {
                    // No stats available - mark as inactive but don't fail
                    await db.node.update({
                        where: { ip: node.ip },
                        data: {
                            status: 'inactive',
                            updatedAt: new Date()
                        }
                    });

                    inactiveNodesCount++;

                    // Create snapshot for inactive node (0 values) to maintain history
                    snapshots.push({
                        nodeIp: node.ip,
                        credits: node.credits || 0,
                        storage: 0,
                        uptime: 0,
                        status: 'inactive',
                        cpuPercent: 0,
                        ramUsage: 0,
                        ramUsed: 0,
                        ramTotal: 0,
                        activeStreams: 0,
                        packetsReceived: 0,
                        packetsSent: 0,
                        timestamp: new Date()
                    });

                    continue;
                }

                // Stats available - node is active
                activeNodesCount++;
                const storageInPB = stats.fileSize ? stats.fileSize / (1024 ** 5) : 0; // PB based on 1024^5? Or standard GB? 
                // Previous code: stats.fileSize / (1024 ** 3) for storage field (Float). 
                // Let's stick to what was there: stats.fileSize / (1024 ** 3). Wait, previously it was:
                // storage: stats.fileSize ? stats.fileSize / (1024 ** 3) : 0
                // Dashboard displays "PB". 
                // If the value is stored as PB, the division should be 1024^5?
                // Actually, let's look at the Dashboard again: value={`${stats.totalStorage.toFixed(2)} PB`}
                // If the individual node storage is small, adding them up to PB might be small.
                // Let's keep consistency with previous code: 1024**3 (GB). If the dashboard says PB, maybe it expects the sum to be large or the unit label is just optimistic.
                // Actually, let's stick to the previous code's logic for individual nodes.

                const storageVal = stats.fileSize ? stats.fileSize / (1024 ** 3) : 0; // GB
                totalNetworkStorage += storageVal;
                totalNetworkCredits += BigInt(node.credits || 0);

                // Update node with fresh stats
                await db.node.update({
                    where: { ip: node.ip },
                    data: {
                        status: 'active',
                        cpuPercent: stats.cpuPercent || 0,
                        ramUsage: stats.ramPercent || 0,
                        ramUsed: stats.ramUsed || 0,
                        ramTotal: stats.ramTotal || 0,
                        activeStreams: stats.activeStreams || 0,
                        packetsReceived: stats.packetsReceived || 0,
                        packetsSent: stats.packetsSent || 0,
                        uptime: stats.uptime || 0,
                        storage: storageVal,
                        updatedAt: new Date()
                    }
                });

                nodesUpdated++;

                // Collect snapshot data
                snapshots.push({
                    nodeIp: node.ip,
                    credits: node.credits || 0,
                    storage: storageVal,
                    uptime: stats.uptime || 0,
                    status: 'active',
                    cpuPercent: stats.cpuPercent || 0,
                    ramUsage: stats.ramPercent || 0,
                    ramUsed: stats.ramUsed || 0,
                    ramTotal: stats.ramTotal || 0,
                    activeStreams: stats.activeStreams || 0,
                    packetsReceived: stats.packetsReceived || 0,
                    packetsSent: stats.packetsSent || 0,
                    timestamp: new Date()
                });

                // Log progress every 50 nodes
                if (nodesProcessed % 50 === 0) {
                    console.log(`  Progress: ${nodesProcessed}/${nodes.length} nodes processed, ${nodesUpdated} updated`);
                }

            } catch (nodeError: any) {
                console.error(`‚ùå Failed to update stats for ${node.ip}:`, nodeError.message);
                errors.push({
                    node: node.ip,
                    error: nodeError.message,
                    phase: 'stats-update'
                });

                // Even on error, if we can't reach it, it might be inactive?
                // For safety, let's treat error as potential inactive but NOT update status to avoid flapping on transient errors.
                // But we should probably NOT create a snapshot if we aren't sure. 

                // Log to database (fire and forget)
                logErrorToDb(
                    'cron/stats-updater',
                    'stats-update',
                    nodeError.message,
                    node.ip,
                    nodeError.stack
                ).catch(() => { });

                // Continue processing other nodes
            }
        }

        console.log(`‚úÖ Processed ${nodesProcessed}/${nodes.length} nodes. Active: ${activeNodesCount}, Inactive: ${inactiveNodesCount}`);

        // Bulk insert snapshots at the end
        if (snapshots.length > 0) {
            try {
                const result = await db.nodeSnapshot.createMany({
                    data: snapshots,
                    skipDuplicates: true
                });
                snapshotsCreated = result.count;
                console.log(`‚úÖ Created ${snapshotsCreated} snapshots`);
            } catch (snapshotError: any) {
                console.error("‚ùå Failed to create snapshots:", snapshotError);
                errors.push({
                    node: 'batch',
                    error: snapshotError.message,
                    phase: 'snapshot'
                });

                logErrorToDb(
                    'cron/stats-updater',
                    'snapshot',
                    snapshotError.message,
                    undefined,
                    snapshotError.stack
                ).catch(() => { });
            }
        }

        // Create NetworkStats record
        try {
            await db.networkStats.create({
                data: {
                    activeNodes: activeNodesCount,
                    inactiveNodes: inactiveNodesCount,
                    totalStorage: totalNetworkStorage,
                    totalCredits: totalNetworkCredits,
                    timestamp: new Date()
                }
            });
            console.log(`‚úÖ Created NetworkStats record`);

            // Refresh the atomic in-memory cache for stats
            try {
                await refreshNetworkStatsCache();
            } catch (cacheError) {
                console.error("‚ö†Ô∏è Failed to refresh stats cache:", cacheError);
            }

        } catch (statsError: any) {
            console.error("‚ùå Failed to create network stats:", statsError);
            logErrorToDb('cron/stats-updater', 'network-stats', statsError.message).catch(() => { });
        }

        const duration = Date.now() - startTime;
        const result = {
            success: true,
            nodesProcessed,
            nodesUpdated,
            snapshotsCreated,
            activeNodes: activeNodesCount,
            inactiveNodes: inactiveNodesCount,
            totalNodes: nodes.length,
            errors: errors.length > 0 ? errors : undefined,
            durationMs: duration,
            message: `Stats updater completed: ${nodesUpdated}/${nodes.length} nodes updated, ${snapshotsCreated} snapshots created`
        };

        console.log(`‚úÖ ${result.message} (${duration}ms)`);
        return NextResponse.json(result);

    } catch (error: any) {
        const duration = Date.now() - startTime;
        console.error("‚ùå Stats updater critical failure:", error);

        // Log critical failure to database
        await logErrorToDb(
            'cron/stats-updater',
            'critical',
            error.message,
            undefined,
            error.stack
        );

        return NextResponse.json({
            success: false,
            error: "Critical failure in stats updater",
            details: error.message,
            stack: process.env.NODE_ENV === 'development' ? error.stack : undefined,
            nodesProcessed,
            nodesUpdated,
            snapshotsCreated,
            errors,
            durationMs: duration
        }, { status: 500 });
    }
}
